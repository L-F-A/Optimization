# Optimization
Few Python optimization routines, first order, 2nd order and stochastic gradient descent

The first and second order methods are direct implementations from the algorithms provided in the notes of

http://ipvs.informatik.uni-stuttgart.de/mlr/marc/teaching/13-Optimization/

Some of the stochastic methods are Python translation of the Matlab codes of Mikhail Pak in

https://github.com/mp4096/adawhatever

The first and second order methods are not better or more efficient than thos provided in minimize() from SciPy, but it is always good to implement stuff just to understand better the methods. Not all the functions have been fully tested yet (second order). Work in progress.


